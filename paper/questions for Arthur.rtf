{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf190
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 questions for Arthur:\
\
statistic for KCI- what would be a consistent meaning of confidence\
conditioning on multiple variables- how does this affect the distribution of the statistic?\
MRF\
geometric interpretation of partial correlation: if variables are marginally independent, then residuals must remain independent..?  Nonlinearity breaks this?\
Is KCI analagous to distance correlation or partial correlation \
\
cov(X,Z) = XHZ^T where H = I - 1/n(11^T)\
\
mu_x|z = C_XZ * C_ZZ^(-1)\
\
copula methods\
Wasserman\
non-paranormal\
\
fat tails\
matern kernels- interpolate between gauss and laplace\
\
MDD\
\
Peter Spiertes Rob Toman.\
NIPS 2009\
KC Algorithm\
\
Lancaster test- can condition on many more variables than in the past\
\
Barnabas Poczos- Copula transform to improve statistical tests\
also does mutual information estimation based on KNN.}